This paper investigates whether a collection of $N$ widely-used large language models (LLMs)
exhibit an echo chamber effect in their generated responses. To quantify response diversity, we
introduce a novel metric: the mean pairwise Jensen–Shannon divergence, $\tau$, computed over the models’
outputs.
